{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Features\n",
    "#### Design Thinking and Predictive Analytics for Data Products\n",
    "\n",
    "This week we were introduced to the concept of features. You can think of features as variables. By definition, features are an individual measurable property or characteristic of a phenomenon being observed. It is important to to choose informative features to enable creating efficient algorithms for pattern recognition, classification, and modeling regression.\n",
    "\n",
    "We then learned about building regressional models that incorporate features from different types of data. In this notebook, we will go over how to capture **categorical and temporal features** within linear regression models. Most questions will be focused on covering the conceptual material in the reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Categorical Features\n",
    "\n",
    "Categorical features can be seen as equivalent to non-numerical data. This can include characteristics such as gender, color, race, etc. Incorporating categorical features into the building of regression models are helpful when analyzing correlation between such non-numerical characteristics. You could look into questions such as how height varies with gender, how product demand changes during different seasons, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The Data\n",
    "\n",
    "Unzip the `BreastCancerData.csv` file in the Week 2 folder. This dataset contains detailed information about the diagnoses of breast masses found in women in Wisconsin. Ten features are calculated about each mass, including radius, smoothness, area, etc. In this portion of the notebook, we will be looking at how we can model the relationship between the radius of a mass and a diagnosis of whether the mass is benign or malignant.\n",
    "\n",
    "### Reading the Data\n",
    "Specify the path of the file. You may need to change the given path according to your local environment. This should be familiar if you took Course 1 (*Basic Data Ingestion, Processing, and Visualization*) of the Python Data Products specialization already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"id\"',\n",
       " '\"diagnosis\"',\n",
       " '\"radius_mean\"',\n",
       " '\"texture_mean\"',\n",
       " '\"perimeter_mean\"',\n",
       " '\"area_mean\"',\n",
       " '\"smoothness_mean\"',\n",
       " '\"compactness_mean\"',\n",
       " '\"concavity_mean\"',\n",
       " '\"concave points_mean\"',\n",
       " '\"symmetry_mean\"',\n",
       " '\"fractal_dimension_mean\"',\n",
       " '\"radius_se\"',\n",
       " '\"texture_se\"',\n",
       " '\"perimeter_se\"',\n",
       " '\"area_se\"',\n",
       " '\"smoothness_se\"',\n",
       " '\"compactness_se\"',\n",
       " '\"concavity_se\"',\n",
       " '\"concave points_se\"',\n",
       " '\"symmetry_se\"',\n",
       " '\"fractal_dimension_se\"',\n",
       " '\"radius_worst\"',\n",
       " '\"texture_worst\"',\n",
       " '\"perimeter_worst\"',\n",
       " '\"area_worst\"',\n",
       " '\"smoothness_worst\"',\n",
       " '\"compactness_worst\"',\n",
       " '\"concavity_worst\"',\n",
       " '\"concave points_worst\"',\n",
       " '\"symmetry_worst\"',\n",
       " '\"fractal_dimension_worst\"',\n",
       " '']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the data\n",
    "import numpy\n",
    "file = open(\"C:/Users/Ian/Documents/PythonDataProducts4PredictiveAnalytics/DesignThinking&PredictiveAnalytics4DataProducts/Final_Course2/datasets/BreastCancerData.csv\",'r')\n",
    "\n",
    "dataset = []\n",
    "header = file.readline().strip().split(',')\n",
    "for line in file:\n",
    "    line = line.split(',')\n",
    "    dataset.append(line)\n",
    "    \n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which column holds the radius mean, our predictor variable?\n",
    "header.index('\"radius_mean\"')\n",
    "print (header.index('\"radius_mean\"')) #This will print the header index.\n",
    "\n",
    "# Which column holds the diagnosis, indicating whether the mass is benign or malignant?\n",
    "header.index('\"diagnosis\"')\n",
    "\n",
    "# When you run this cell, both indexes should show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a: Model Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, we created a model equation based on the example of height varying with gender. We had 4 values for gender: {\"male\", \"female\", \"other\", \"not specified.\"} We represented gender with numerical values. 0 if \"male\", 1 if \"female\", 2 if \"other\", 3 if \"not specified.\" Our equations were: \n",
    "\n",
    "$Height = ùúÉ‚ÇÄ$ if male <br> \n",
    "$Height = ùúÉ‚ÇÄ + ùúÉ‚ÇÅ$ if female <br>\n",
    "$Height = ùúÉ‚ÇÄ + ùúÉ‚ÇÇ$ if other <br>\n",
    "$Height = ùúÉ‚ÇÄ + ùúÉ‚ÇÉ$ if not specified <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius = ùúÉ‚ÇÄ if benign\n",
      "radius = ùúÉ‚ÇÄ + ùúÉ‚ÇÅ if malignant\n"
     ]
    }
   ],
   "source": [
    "# What would the model equations for what we are looking for? Assume 0 is \"benign.\"\n",
    "\n",
    "print(\"radius = ùúÉ‚ÇÄ if benign\")\n",
    "print(\"radius = ùúÉ‚ÇÄ + ùúÉ‚ÇÅ if malignant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Temporal Features\n",
    "Temporal features are variables that have to do with time. We can use them to look at patterns such as how sales vary over time, long term trends in sales, or short term trends such as weekly preferences.\n",
    "\n",
    "### Data\n",
    "Unzip the `temperature.csv` file in the Week 2 folder. This dataset contains hourly temperature data over the course of ~5 years from 36 different cities.\n",
    "\n",
    "### Reading the Data\n",
    "Specify the path of the file. You may need to change the given path according to your local environment. This should be familiar if you took Course 1 (*Basic Data Ingestion, Processing, and Visualization*) of the Python Data Products specialization already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'Vancouver',\n",
       " 'Portland',\n",
       " 'San Francisco',\n",
       " 'Seattle',\n",
       " 'Los Angeles',\n",
       " 'San Diego',\n",
       " 'Las Vegas',\n",
       " 'Phoenix',\n",
       " 'Albuquerque',\n",
       " 'Denver',\n",
       " 'San Antonio',\n",
       " 'Dallas',\n",
       " 'Houston',\n",
       " 'Kansas City',\n",
       " 'Minneapolis',\n",
       " 'Saint Louis',\n",
       " 'Chicago',\n",
       " 'Nashville',\n",
       " 'Indianapolis',\n",
       " 'Atlanta',\n",
       " 'Detroit',\n",
       " 'Jacksonville',\n",
       " 'Charlotte',\n",
       " 'Miami',\n",
       " 'Pittsburgh',\n",
       " 'Toronto',\n",
       " 'Philadelphia',\n",
       " 'New York',\n",
       " 'Montreal',\n",
       " 'Boston',\n",
       " 'Beersheba',\n",
       " 'Tel Aviv District',\n",
       " 'Eilat',\n",
       " 'Haifa',\n",
       " 'Nahariyya',\n",
       " 'Jerusalem']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process the data\n",
    "import numpy\n",
    "file = open(\"C:/Users/Ian/Documents/PythonDataProducts4PredictiveAnalytics/DesignThinking&PredictiveAnalytics4DataProducts/Final_Course2/datasets/temperature.csv\",'r')\n",
    "\n",
    "dataset = []\n",
    "header = file.readline().strip().split(',')\n",
    "for line in file:\n",
    "    line = line.split(',')\n",
    "    dataset.append(line)\n",
    "    \n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just reviewing\n",
    "# Which column holds the temperatures for Chicago?\n",
    "header.index('Chicago')\n",
    "print (header.index('Chicago')) #This will print the header index.\n",
    "\n",
    "# Which column holds the temperatures for Eilat?\n",
    "header.index('Eilat')\n",
    "\n",
    "# When you run this cell, both indexes should show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Since we are looking at multiple years of data, what class of functions must be use to capture the flexible shape this data creates? <br>\n",
    "*A: Piece-wise functions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Create a function for monthly temperature data. (Hint: Similar to the equation for monthly ratings over time) How would we list the feature vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Missing Values\n",
    "\n",
    "In this lecture, we learned about issues dealing with datasets that are missing values, and we looked at different strategies for dealing with those missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been dealing with missing values by discarding those instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do you recall this method?\n",
    "dataset = [d for d in dataset if d[5] != 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We covered three strategies for dealing with missing data:\n",
    "1. **Filtering:** discarding missing values (above method)\n",
    "2. **Missing data imputation:** filling in the missing values with \"reasonable\" estimates\n",
    "3. **Modeling:** changing our regression/classification algorithms to handle missing data explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3a: Missing Data Imputation\n",
    "\n",
    "[Scikit learn: Imputation of Missing Values](https://scikit-learn.org/stable/modules/impute.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Source: https://openmv.net/info/travel-times\n",
    "\n",
    "Unzip the `travel-times.csv` file in the Week 2 folder. This dataset contains about the data for about 200 trips a driver took back and forth each day. He uses an app to track GPS coordinates which collects location and elevation data. Some examples of the data include date, start time, day of the week, direction of travel, distance, etc. \n",
    "\n",
    "### Reading the Data\n",
    "Specify the path of the file. You may need to change the given path according to your local environment. This should be familiar if you took Course 1 (*Basic Data Ingestion, Processing, and Visualization*) of the Python Data Products specialization already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'StartTime',\n",
       " 'DayOfWeek',\n",
       " 'GoingTo',\n",
       " 'Distance',\n",
       " 'MaxSpeed',\n",
       " 'AvgSpeed',\n",
       " 'AvgMovingSpeed',\n",
       " 'FuelEconomy',\n",
       " 'TotalTime',\n",
       " 'MovingTime',\n",
       " 'Take407All',\n",
       " 'Comments']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "file = open(\"C:/Users/Ian/Documents/PythonDataProducts4PredictiveAnalytics/DesignThinking&PredictiveAnalytics4DataProducts/Final_Course2/datasets/travel-times.csv\", 'r')\n",
    "\n",
    "dataset = []\n",
    "header = file.readline().strip().split(',')\n",
    "for line in file:\n",
    "    line = line.split(',')\n",
    "    dataset.append(line)\n",
    "    \n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the `travel-times.csv` dataset and make observations about the dataset. You can also use the following method to view some of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0          1          2        3         4         5         6   \\\n",
      "0         Date  StartTime  DayOfWeek  GoingTo  Distance  MaxSpeed  AvgSpeed   \n",
      "1     1/6/2012      16:37     Friday     Home     51.29     127.4      78.3   \n",
      "2     1/6/2012      08:20     Friday      GSK     51.63     130.3      81.8   \n",
      "3     1/4/2012      16:17  Wednesday     Home     51.27     127.4      82.0   \n",
      "4     1/4/2012      07:53  Wednesday      GSK     49.17     132.3      74.2   \n",
      "5     1/3/2012      18:57    Tuesday     Home     51.15     136.2      83.4   \n",
      "6     1/3/2012      07:57    Tuesday      GSK     51.80     135.8      84.5   \n",
      "7     1/2/2012      17:31     Monday     Home     51.37     123.2      82.9   \n",
      "8     1/2/2012      07:34     Monday      GSK     49.01     128.3      77.5   \n",
      "9   12/23/2011      08:01     Friday      GSK     52.91     130.3      80.9   \n",
      "10  12/22/2011      17:19   Thursday     Home     51.17     122.3      70.6   \n",
      "11  12/22/2011      08:16   Thursday      GSK     49.15     129.4      74.0   \n",
      "12  12/21/2011      07:45  Wednesday      GSK     51.77     124.8      71.7   \n",
      "13  12/20/2011      16:05    Tuesday     Home     51.45     130.1      75.2   \n",
      "14  12/20/2011      06:04    Tuesday      GSK     49.01     119.0      77.4   \n",
      "15  12/19/2011      16:18     Monday     Home     51.04     132.2      77.5   \n",
      "16  12/19/2011      07:34     Monday      GSK     52.00     137.8      76.5   \n",
      "17  12/16/2011      12:22     Friday     Home     51.05     128.4      86.9   \n",
      "18  12/16/2011      07:21     Friday      GSK     49.04     124.6      71.1   \n",
      "19  12/15/2011      16:14   Thursday     Home     51.06     126.9      80.5   \n",
      "\n",
      "                7            8          9           10          11  \\\n",
      "0   AvgMovingSpeed  FuelEconomy  TotalTime  MovingTime  Take407All   \n",
      "1             84.8          NaN       39.3        36.3          No   \n",
      "2             88.9          NaN       37.9        34.9          No   \n",
      "3             85.8          NaN       37.5        35.9          No   \n",
      "4             82.9          NaN       39.8        35.6          No   \n",
      "5             88.1          NaN       36.8        34.8          No   \n",
      "6             88.8          NaN       36.8        35.0          No   \n",
      "7             87.3            -       37.2        35.3          No   \n",
      "8             85.9            -       37.9        34.3          No   \n",
      "9             88.3         8.89       39.3        36.0          No   \n",
      "10            78.1         8.89       43.5        39.3          No   \n",
      "11            81.4         8.89       39.8        36.2          No   \n",
      "12            78.9         8.89       43.3        39.4          No   \n",
      "13            82.7         8.89       41.1        37.3          No   \n",
      "14            82.0         8.89       38.0        35.9          No   \n",
      "15            83.5         8.89       39.5        36.7          No   \n",
      "16            87.8         8.89       40.8        35.5          No   \n",
      "17            90.6         9.08       35.2        33.8          No   \n",
      "18            80.2         9.08       41.4        36.7          No   \n",
      "19            84.9         9.08       38.1        36.1          No   \n",
      "\n",
      "                   12  \n",
      "0            Comments  \n",
      "1                 NaN  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4                 NaN  \n",
      "5                 NaN  \n",
      "6                 NaN  \n",
      "7                 NaN  \n",
      "8                 NaN  \n",
      "9                 NaN  \n",
      "10                NaN  \n",
      "11                NaN  \n",
      "12                NaN  \n",
      "13                NaN  \n",
      "14                NaN  \n",
      "15                NaN  \n",
      "16  Put snow tires on  \n",
      "17                NaN  \n",
      "18                NaN  \n",
      "19                NaN  \n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy\n",
    "dataset = read_csv('C:/Users/Ian/Documents/PythonDataProducts4PredictiveAnalytics/DesignThinking&PredictiveAnalytics4DataProducts/Final_Course2/datasets/travel-times.csv', header=None)\n",
    "# print the first 20 rows of data\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about this dataset, specifically Columns 8 and 12? <br>\n",
    "*You can see that there are missing values, indicated by NaN.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like, you can use the scikit documentation link above to try out missing data imputation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b: Modeling Missing Data\n",
    "\n",
    "Review Question: <br> \n",
    "In an earlier example, we had a male feature and a female feature. We represented this by writing:<br>\n",
    "<center>feature=[1,0,0] for \"female\"</center>\n",
    "<center>feature=[0,1,0] for \"male\"</center>\n",
    "Q: Add an additional feature to indicate that a value is missing.<br>\n",
    "*A: feature = [0,0,1] for \"feature missing\"*<br>\n",
    "*Think about it:* What predicts does this model make under this scheme?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This portion of the homework is simply a review of the lecture reading.\n",
    "\n",
    "Review Question:\n",
    "When looking at weight vs height and using a polynomial equation to model this relationship, you can use the equation <center>$weight=ùúÉ‚ÇÄ+ùúÉ‚ÇÅ*height+ùúÉ‚ÇÇ*height^2+ùúÉ‚ÇÉ*height^3$</center> <br>\n",
    "This equation still takes the form of $weight=ùúÉ*x$. <br>\n",
    "Q: We need to use the feature vector. What would it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [1, height, height^2, height^3]\n"
     ]
    }
   ],
   "source": [
    "#Answer\n",
    "print(\"x = [1, height, height^2, height^3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restriction: Linear models do not support transformations such as       (https://imgur.com/a/kHP49uy). This is wher eyou would use alternative models that support nonlinear transformations such as neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## You're all done!\n",
    "You should be familiar with what categorical and temporal data are and what to do when you are missing values. Try using what you know about regression and these types of features to run your own regressions! Perhaps try predicting a categorical value based on some numerical data, or analyze some type of data over time. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
